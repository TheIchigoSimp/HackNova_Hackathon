# Resume Agent Service Architecture (FastAPI/LangGraph)

> **Location**: `resume_agent_service/` | **Port**: 8001 | **Framework**: FastAPI + LangGraph

---

## ğŸ“ Directory Structure

```
resume_agent_service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI endpoints + SSE streaming
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                   # Configuration & state
â”‚   â”‚   â”œâ”€â”€ config.py           # Environment config
â”‚   â”‚   â””â”€â”€ state.py            # LangGraph agent state schema
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/                  # LangGraph agent definition
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ builder.py          # Graph construction
â”‚   â”‚   â””â”€â”€ nodes.py            # Agent nodes (think, act, respond)
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                 # Session persistence
â”‚   â”‚   â”œâ”€â”€ checkpointer.py     # Async SQLite checkpointer
â”‚   â”‚   â””â”€â”€ thread_manager.py   # Thread ID management
â”‚   â”‚
â”‚   â”œâ”€â”€ services/               # Business logic
â”‚   â”‚   â””â”€â”€ resume_ingestion.py # PDF parsing & vectorization
â”‚   â”‚
â”‚   â””â”€â”€ tools/                  # Agent tools
â”‚       â”œâ”€â”€ __init__.py         # Tool exports
â”‚       â”œâ”€â”€ rag_tool.py         # Resume RAG queries
â”‚       â”œâ”€â”€ ats_scorer.py       # ATS compatibility scoring
â”‚       â””â”€â”€ web_search_tool.py  # Job search via DuckDuckGo
â”‚
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md
```

---

## ğŸ¤– LangGraph Agent Architecture

```mermaid
graph TD
    subgraph Agent["LangGraph Agent"]
        START((Start)) --> Think[Think Node]
        Think --> |"Need Tool"| Act[Act Node]
        Act --> Think
        Think --> |"Have Answer"| Respond[Respond Node]
        Respond --> END((End))
    end

    subgraph Tools["Available Tools"]
        RAG[query_resume_knowledge]
        ATS[calculate_ats_score]
        Search[search_jobs]
    end

    Act --> RAG
    Act --> ATS
    Act --> Search
    RAG --> |"Results"| Act
    ATS --> |"Score"| Act
    Search --> |"Jobs"| Act
```

---

## ğŸ”Œ API Endpoints

### `POST /upload`
Upload and process a PDF resume.

**Request:**
```json
{
  "file": "<PDF binary>",
  "thread_id": "optional-existing-thread-id"
}
```

**Response:**
```json
{
  "success": true,
  "thread_id": "abc123",
  "message": "Resume processed successfully",
  "ats_score": 75,
  "suggestions": ["Add more keywords", "Improve formatting"]
}
```

---

### `POST /chat` (SSE Streaming)
Chat with the AI about the resume.

**Request:**
```json
{
  "thread_id": "abc123",
  "message": "What jobs match my skills?"
}
```

**Response:** Server-Sent Events (SSE)
```
data: {"type": "token", "content": "Based"}
data: {"type": "token", "content": " on"}
data: {"type": "token", "content": " your"}
...
data: {"type": "done", "content": ""}
```

---

### `GET /health`
Health check endpoint.

**Response:**
```json
{
  "status": "healthy"
}
```

---

## ğŸ§  Agent State Schema

```python
class AgentState(TypedDict):
    messages: Annotated[list, add_messages]  # Chat history
    resume_text: str                          # Parsed resume content
    ats_score: Optional[int]                  # ATS compatibility score
    thread_id: str                            # Session identifier
```

---

## ğŸ”§ Tools Reference

### `query_resume_knowledge`
RAG tool to search the vectorized resume content.

```python
def query_resume_knowledge(query: str, thread_id: str) -> str:
    """
    Search the resume for relevant information.
    Uses FAISS vector store for semantic search.
    """
```

### `calculate_ats_score`
Analyze resume for ATS compatibility.

```python
def calculate_ats_score(resume_text: str) -> dict:
    """
    Returns:
    - score: 0-100 ATS compatibility score
    - suggestions: List of improvement recommendations
    - keyword_analysis: Missing/present keywords
    """
```

### `search_jobs`
Search for matching job opportunities.

```python
def search_jobs(skills: list[str], location: str = "") -> list[dict]:
    """
    Uses DuckDuckGo to find job listings.
    Returns: List of job objects with title, company, url
    """
```

---

## ğŸ’¾ Memory & Persistence

```mermaid
graph LR
    subgraph Session Management
        Client([Client])
        ThreadID[Thread ID]
        Checkpointer[Async SQLite]
        State[Agent State]
    end

    Client -->|"thread_id"| ThreadID
    ThreadID --> Checkpointer
    Checkpointer --> State
    State -->|"Resume"| FAISS[(FAISS Vector Store)]
```

### Thread Management
- Each resume upload creates a new `thread_id`
- Thread ID links: chat history, resume vectors, ATS score
- SQLite checkpointer persists LangGraph state
- FAISS stores resume embeddings per thread

---

## ğŸ“Š Data Flow

```mermaid
sequenceDiagram
    participant Client
    participant FastAPI
    participant LangGraph
    participant Tools
    participant Groq

    Client->>FastAPI: POST /upload (PDF)
    FastAPI->>FastAPI: Parse PDF â†’ text
    FastAPI->>FAISS: Vectorize & store
    FastAPI->>Tools: calculate_ats_score()
    Tools-->>FastAPI: {score, suggestions}
    FastAPI-->>Client: {thread_id, ats_score}

    Client->>FastAPI: POST /chat (message)
    FastAPI->>LangGraph: invoke(message)
    LangGraph->>Groq: Generate response
    loop Streaming
        Groq-->>LangGraph: Token
        LangGraph-->>FastAPI: Token
        FastAPI-->>Client: SSE event
    end
    FastAPI-->>Client: SSE done
```

---

## ğŸ“¦ Key Dependencies

| Package | Purpose |
|---------|---------|
| `fastapi` | Web framework |
| `langgraph` | Agent orchestration |
| `langchain` | LLM utilities |
| `langchain-groq` | Groq LLM integration |
| `faiss-cpu` | Vector similarity search |
| `pypdf2` | PDF text extraction |
| `duckduckgo-search` | Web search |
| `sse-starlette` | Server-sent events |

---

## âœ… Adding New Features Checklist

1. [ ] **New Tool**: Add to `app/tools/`, export in `__init__.py`, bind to agent in `builder.py`
2. [ ] **New Endpoint**: Add to `app/main.py`
3. [ ] **State Changes**: Update `core/state.py`, adjust nodes in `graph/nodes.py`
4. [ ] **New Node**: Add to `graph/nodes.py`, wire in `graph/builder.py`
5. [ ] Update this documentation

---

## ğŸ› Debugging Tips

1. **Check logs**: All LangGraph nodes log to console
2. **Test tools independently**: Import and call tools directly
3. **Inspect state**: Use `checkpointer.get()` to view saved state
4. **Streaming issues**: Check SSE connection in browser DevTools
